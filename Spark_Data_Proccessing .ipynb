{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing With Pyspark\n",
    "## Preamble\n",
    "This ananlysis including three steps, **data Processing**, **exploratory data analysis** and **model building**. This notebook is the first part of analysis, processing raw data of taxi transaction in NYC. The report includes follow aspects:\n",
    "- Desription of original dataset \n",
    "- Data cleaning and processing \n",
    "- Feature engineering \n",
    "- Summary of the output dataset\n",
    "Since the dataset is too large to process in the local python. Hadoop HDFS and Pyspark were adopted in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of original dataset\n",
    "As mentioned previously, the dataset is about NYC taxi transaction. The original dataset is provided by **NYC Taxi & Limousine Commission**. (http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml) In this case, only tansaction between 2016 to 2018 were used. There are three type of taxis tansaction provided on the site, Green, Yellow and FHV. See the descriptions of three types of taxi below.\n",
    "\n",
    "|Index |Taxi Type  | Description | \n",
    "| :----------:|:----------: |:---------------------------------------------------------------:|\n",
    "|1| Green| Hybrid between yellow taxis and FHV, permitted to additionally accept street-hails outside Manhattan |\n",
    "|2| Yellow| Tranditional NYC taxis that provide transportation exclusively through street-hails. |\n",
    "|3| FHV| Community car services (livery), black car services, or luxury limo services. |\n",
    "\n",
    "In this analysis, only data of **Yellow** and **Green** taxis were used because the FHV transaction didn't contain enough information for analysis. There are 6 total csv files for this analysis(Green and Yellow for each year).Noted that the data of 2018 only contain half year of transaction since the website update files semiannually. These 6 datasets mainly incuding follow information:\n",
    "- **VendorID**: A code indicating the LPEP provider that provided the record. \n",
    "- **lpep_pickup_datetime**: The date and time when the meter was engaged.\n",
    "- **Lpep_dropoff_datetime**: The date and time when the meter was disengaged. \n",
    "- **Passenger_count** : The number of passengers in the vehicle. This is a driver-entered value.\n",
    "- **PULocationID** : Taxi Zone in which the taximeter was engaged\n",
    "- **DOLocationID** : Taxi Zone in which the taximeter was disengaged\n",
    "- **RateCodeID** : The final rate code in effect at the end of the trip.\n",
    "- **Store_and_fwd_flag** : This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, because the vehicle did not have a connection to the server.\n",
    "- **Payment_type** : A numeric code signifying how the passenger paid for the trip. \n",
    "- **Fare_amount** : The time-and-distance fare calculated by the meter. \n",
    "- **Extra** : Miscellaneous extras and surcharges. Currently, this only includes the 0.50 and 1 rush hour and overnight charges.\n",
    "- **MTA_tax** : 0.50 MTA tax that is automatically triggered based on the metered rate in use.\n",
    "- **Improvement_surcharge** : 0.30 improvement surcharge assessed on hailed trips at the flag drop. The improvement surcharge began in 2015.\n",
    "- **Tip_amount** : This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "- **Tolls_amount** : Total amount of all tolls paid in trip. \n",
    "- **Total_amount** : The total amount charged to passengers. Does not include cash tips.\n",
    "- **Trip_type** : A code indicating whether the trip was a street-hail or a dispatch that is automatically assigned based on the metered rate in use but can be altered by the driver.\n",
    "\n",
    "Since there are some noises in the original datasets, plus there are some features irrelevant to the analysis. Some measures of  data cleaning and processing must be implemented to get the datasets ready for futher analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and processing \n",
    "Since the files are really huge(over 50GB), some pre-processing were made to reduce the overall size, including dropping columns irrelevant to the analysis and take out rows that have different numbers of columns. After the pre-processing, the files were upload to the Haddoop HDFS to begin the data cleaning and processing. The process of data cleaning includes follow steps:\n",
    "- **Deploy Spark cluster and read mutiple csv files**\n",
    "- **Check and handle missing value** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Spark cluster and read files\n",
    "Since we are using **Hadoop Distributed File System** to store our data and **PySpark** to perform analysis, it is important to set a full-fledged Hadoop cluster and use **Yarn** to deploy the cluster. In this case, 63 instances were used for computing.\n",
    "\n",
    "There are 6 files to analysis, so we decided to read them to separete dataframes and processe them separately, and the process is over, these dataframe would be combined together for exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 174 ms, sys: 141 ms, total: 315 ms\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#init\n",
    "#set path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sqrt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types\n",
    "import os\n",
    "import subprocess\n",
    "mypath = \"/user/hadoop/NYCTaxi/16-18\" #your dir\n",
    "cmd = ('hdfs dfs -ls '+mypath).split()\n",
    "files = subprocess.check_output(cmd).strip().split()[3:]\n",
    "fullpath=[]\n",
    "for i in range(7,len(files),8):\n",
    "    fullpath.append(str(files[i])[2:-1])\n",
    "files=[i[27:] for i in fullpath]\n",
    "df = ['PU_Time','DO_Time','Trip_Distance','Rate_Code','PU_Lon','PU_Lat','DO_Lon','DO_Lat','Fare_Amt','Extra','Tip_Amt','PULocationID','DOLocationID']\n",
    "fullpath=fullpath[6:-1]\n",
    "files=files[6:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目錄下的檔案有:\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2016_Green.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2016_Yellow.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2017_Green.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2017_Yellow.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Green-01.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Green-02.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Green-03.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Green-04.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Green-05.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Green-06.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Yellow-01.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Yellow-02.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Yellow-03.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Yellow-04.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Yellow-05.csv\n",
      "/user/hadoop/NYCTaxi/16-18/cleaned_2018_Yellow-06.csv\n",
      "第一個檔案的原始欄位\n",
      "16385532 13\n",
      "---------\n",
      "[('PU_Time', 'string'), ('DO_Time', 'string'), ('Rate_Code', 'int'), ('PU_Lon', 'double'), ('PU_Lat', 'double'), ('DO_Lon', 'double'), ('DO_Lat', 'double'), ('Trip_Distance', 'double'), ('Fare_Amt', 'double'), ('Extra', 'double'), ('Tip_Amt', 'double'), ('PULocationID', 'int'), ('DOLocationID', 'int')]\n",
      "CPU times: user 108 ms, sys: 32.3 ms, total: 141 ms\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#infile\n",
    "spark = SparkSession.builder.master(\"yarn\").config('spark.executor.instances','48').appName(\"badass\").getOrCreate()\n",
    "print('目錄下的檔案有:')\n",
    "t=[]\n",
    "for  f in fullpath:\n",
    "    print(f)\n",
    "    t += [spark.read.csv(f,sep = ',',header = True,inferSchema = True)]\n",
    "df0=t[0]\n",
    "print('第一個檔案的原始欄位')\n",
    "print(df0.count(),len(df0.columns))\n",
    "print('---------')\n",
    "print(df0.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and handle missing values\n",
    "Since there are sufficient data for analysis, all rows with missing vlaue were dropped by decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Check NA values\n",
    "for i in range(0,len(t)):\n",
    "    for col in df:\n",
    "        if col not in t[i].columns:\n",
    "            print('Table',files[i],'do not have column', col)\n",
    "        else:\n",
    "            tmp=t[i].filter(t[i][col].isNull()).count()\n",
    "            if tmp!=0:\n",
    "                print('In table',files[i],'column',col,'has',tmp,'NA values.')\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 ms, sys: 387 µs, total: 26.5 ms\n",
      "Wall time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Handle NA values\n",
    "for i in range(2):\n",
    "    for j in ['PU_Lon','PU_Lat','DO_Lon','DO_Lat']:\n",
    "        t[i]=t[i].drop(j)\n",
    "\n",
    "#Drop few NA rows\n",
    "for i in range(0,len(t)):\n",
    "     t[i] = t[i].na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After dropping rows with missing value, the shape of all csv files were checked to see if they still have sufficient data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_2016_Green.csv [7367502, 9]\n",
      "cleaned_2016_Yellow.csv [61758523, 9]\n",
      "cleaned_2017_Green.csv [11740667, 9]\n",
      "cleaned_2017_Yellow.csv [113496874, 9]\n",
      "cleaned_2018_Green-01.csv [793529, 9]\n",
      "cleaned_2018_Green-02.csv [769940, 9]\n",
      "cleaned_2018_Green-03.csv [837149, 9]\n",
      "cleaned_2018_Green-04.csv [800084, 9]\n",
      "cleaned_2018_Green-05.csv [797233, 9]\n",
      "cleaned_2018_Green-06.csv [739373, 9]\n",
      "cleaned_2018_Yellow-01.csv [8759874, 9]\n",
      "cleaned_2018_Yellow-02.csv [8492076, 9]\n",
      "cleaned_2018_Yellow-03.csv [9430376, 9]\n",
      "cleaned_2018_Yellow-04.csv [9305515, 9]\n",
      "cleaned_2018_Yellow-05.csv [9224063, 9]\n",
      "cleaned_2018_Yellow-06.csv [8713831, 9]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(t)):\n",
    "    print(files[i],[t[i].count(),len(t[i].columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering \n",
    "After the basic data processing, the step of feature engineering took place to get further imformation of the original dataset. The process of Feature engineering includes follow steps:\n",
    "- Feature extraction \n",
    "- Check and handle values that don't make logical sense\n",
    "- Check and handle outlier\n",
    "- Combine all the dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 ms, sys: 14.2 ms, total: 43.5 ms\n",
      "Wall time: 826 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#New Columns\n",
    "\n",
    "\n",
    "# timeDiff = (F.unix_timestamp('EndDateTime')\n",
    "#             - F.unix_timestamp('StartDateTime'))\n",
    "# df = df.withColumn(\"Duration\", timeDiff)\n",
    "\n",
    "for i in range(len(t)):\n",
    "    t[i]=t[i].withColumn('PU_Time',F.unix_timestamp(t[i]['PU_Time'], 'MM/dd/yyyy h:mm:ss a').cast('timestamp'))\n",
    "    t[i]=t[i].withColumn('DO_Time',F.unix_timestamp(t[i]['DO_Time'], 'MM/dd/yyyy h:mm:ss a').cast('timestamp'))\n",
    "\n",
    "\n",
    "for i in range(len(t)):\n",
    "    tt = F.unix_timestamp(t[i].DO_Time)-F.unix_timestamp(t[i].PU_Time)\n",
    "    t[i] = t[i].withColumn('Trip_Time', tt)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction \n",
    "When analyzing traffic, time is always a critical factor. In this analysis, the Pick Up time, which means the begining time of a transaction, was breakdown to several categorical features: Year, Month, Day, Hour, Minute, Second, WeekDay with the attempt to find the specific period of time when the duration of the taxi rides were affected by the traffic.\n",
    "In addition, the speed were calculated to if there were peculiar value between time and distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "Row(PU_Time=datetime.datetime(2016, 7, 1, 0, 38, 47), DO_Time=datetime.datetime(2016, 7, 1, 0, 40, 53), Rate_Code=1, Trip_Distance=1.11044736, Fare_Amt=-4.0, Extra=-0.5, Tip_Amt=0.0, PULocationID=95, DOLocationID=95, Trip_Time=126, PU_Year=2016, PU_Month=7, PU_Day=1, PU_Hour=0, PU_Minute=38, PU_Second=47, PU_WeekDay=6, Speed=31.727067428571427)\n"
     ]
    }
   ],
   "source": [
    "#PU_Year\n",
    "#PU_Month\n",
    "#PU_Day\n",
    "#PU_Hour\n",
    "#PU_Minute\n",
    "#PU_Second\n",
    "#PU_WeekDay(0:6)\n",
    "#Trip_Distance :miles to km\n",
    "#Speed(km/hr)\n",
    "for i in range(len(t)):\n",
    "    t[i] = t[i].withColumn('PU_Year',F.year(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Month',F.month(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Day',F.dayofmonth(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Hour',F.hour(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Minute',F.minute(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Second',F.second(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_WeekDay',F.dayofweek(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('Trip_Distance',t[i].Trip_Distance*1.609344)\n",
    "    t[i] = t[i].withColumn('Speed',t[i].Trip_Distance*3600/t[i].Trip_Time)\n",
    "print(t[0].columns)\n",
    "print(t[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and handle values that don't make logical sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_2016_Green.csv\n",
      "Trip_Time<=0 的資料有 5103 筆\n",
      "Trip_Distance<=0 的資料有 99175 筆\n",
      "Fare_Amt<0 的資料有 99175 筆\n",
      "df0.Extra<0 的資料有 7904 筆\n",
      "Tip_Amt<0 的資料有 127 筆\n",
      "\n",
      "Total: 127550\n",
      "---------------------------------\n",
      "cleaned_2016_Yellow.csv\n",
      "Trip_Time<=0 的資料有 64171 筆\n",
      "Trip_Distance<=0 的資料有 377078 筆\n",
      "Fare_Amt<0 的資料有 377078 筆\n",
      "df0.Extra<0 的資料有 13632 筆\n",
      "Tip_Amt<0 的資料有 482 筆\n",
      "\n",
      "Total: 483790\n",
      "---------------------------------\n",
      "cleaned_2017_Green.csv\n",
      "Trip_Time<=0 的資料有 6694 筆\n",
      "Trip_Distance<=0 的資料有 135743 筆\n",
      "Fare_Amt<0 的資料有 135743 筆\n",
      "df0.Extra<0 的資料有 14104 筆\n",
      "Tip_Amt<0 的資料有 208 筆\n",
      "\n",
      "Total: 183388\n",
      "---------------------------------\n",
      "cleaned_2017_Yellow.csv\n",
      "Trip_Time<=0 的資料有 108458 筆\n",
      "Trip_Distance<=0 的資料有 743152 筆\n",
      "Fare_Amt<0 的資料有 743152 筆\n",
      "df0.Extra<0 的資料有 27486 筆\n",
      "Tip_Amt<0 的資料有 844 筆\n",
      "\n",
      "Total: 936029\n",
      "---------------------------------\n",
      "cleaned_2018_Green-01.csv\n",
      "Trip_Time<=0 的資料有 462 筆\n",
      "Trip_Distance<=0 的資料有 9216 筆\n",
      "Fare_Amt<0 的資料有 9216 筆\n",
      "df0.Extra<0 的資料有 1017 筆\n",
      "Tip_Amt<0 的資料有 13 筆\n",
      "\n",
      "Total: 12647\n",
      "---------------------------------\n",
      "cleaned_2018_Green-02.csv\n",
      "Trip_Time<=0 的資料有 353 筆\n",
      "Trip_Distance<=0 的資料有 7703 筆\n",
      "Fare_Amt<0 的資料有 7703 筆\n",
      "df0.Extra<0 的資料有 971 筆\n",
      "Tip_Amt<0 的資料有 12 筆\n",
      "\n",
      "Total: 10890\n",
      "---------------------------------\n",
      "cleaned_2018_Green-03.csv\n",
      "Trip_Time<=0 的資料有 432 筆\n",
      "Trip_Distance<=0 的資料有 8776 筆\n",
      "Fare_Amt<0 的資料有 8776 筆\n",
      "df0.Extra<0 的資料有 1171 筆\n",
      "Tip_Amt<0 的資料有 12 筆\n",
      "\n",
      "Total: 12578\n",
      "---------------------------------\n",
      "cleaned_2018_Green-04.csv\n",
      "Trip_Time<=0 的資料有 374 筆\n",
      "Trip_Distance<=0 的資料有 8947 筆\n",
      "Fare_Amt<0 的資料有 8947 筆\n",
      "df0.Extra<0 的資料有 1025 筆\n",
      "Tip_Amt<0 的資料有 10 筆\n",
      "\n",
      "Total: 12386\n",
      "---------------------------------\n",
      "cleaned_2018_Green-05.csv\n",
      "Trip_Time<=0 的資料有 363 筆\n",
      "Trip_Distance<=0 的資料有 9783 筆\n",
      "Fare_Amt<0 的資料有 9783 筆\n",
      "df0.Extra<0 的資料有 884 筆\n",
      "Tip_Amt<0 的資料有 12 筆\n",
      "\n",
      "Total: 13035\n",
      "---------------------------------\n",
      "cleaned_2018_Green-06.csv\n",
      "Trip_Time<=0 的資料有 373 筆\n",
      "Trip_Distance<=0 的資料有 8234 筆\n",
      "Fare_Amt<0 的資料有 8234 筆\n",
      "df0.Extra<0 的資料有 912 筆\n",
      "Tip_Amt<0 的資料有 6 筆\n",
      "\n",
      "Total: 11445\n",
      "---------------------------------\n",
      "cleaned_2018_Yellow-01.csv\n",
      "Trip_Time<=0 的資料有 7620 筆\n",
      "Trip_Distance<=0 的資料有 55376 筆\n",
      "Fare_Amt<0 的資料有 55376 筆\n",
      "df0.Extra<0 的資料有 2106 筆\n",
      "Tip_Amt<0 的資料有 55 筆\n",
      "\n",
      "Total: 69417\n",
      "---------------------------------\n",
      "cleaned_2018_Yellow-02.csv\n",
      "Trip_Time<=0 的資料有 7197 筆\n",
      "Trip_Distance<=0 的資料有 52242 筆\n",
      "Fare_Amt<0 的資料有 52242 筆\n",
      "df0.Extra<0 的資料有 2186 筆\n",
      "Tip_Amt<0 的資料有 54 筆\n",
      "\n",
      "Total: 66086\n",
      "---------------------------------\n",
      "cleaned_2018_Yellow-03.csv\n",
      "Trip_Time<=0 的資料有 7777 筆\n",
      "Trip_Distance<=0 的資料有 60898 筆\n",
      "Fare_Amt<0 的資料有 60898 筆\n",
      "df0.Extra<0 的資料有 2620 筆\n",
      "Tip_Amt<0 的資料有 70 筆\n",
      "\n",
      "Total: 76641\n",
      "---------------------------------\n",
      "cleaned_2018_Yellow-04.csv\n",
      "Trip_Time<=0 的資料有 7531 筆\n",
      "Trip_Distance<=0 的資料有 57651 筆\n",
      "Fare_Amt<0 的資料有 57651 筆\n",
      "df0.Extra<0 的資料有 2357 筆\n",
      "Tip_Amt<0 的資料有 58 筆\n",
      "\n",
      "Total: 72572\n",
      "---------------------------------\n",
      "cleaned_2018_Yellow-05.csv\n",
      "Trip_Time<=0 的資料有 7647 筆\n",
      "Trip_Distance<=0 的資料有 59137 筆\n",
      "Fare_Amt<0 的資料有 59137 筆\n",
      "df0.Extra<0 的資料有 2519 筆\n",
      "Tip_Amt<0 的資料有 62 筆\n",
      "\n",
      "Total: 74574\n",
      "---------------------------------\n",
      "cleaned_2018_Yellow-06.csv\n",
      "Trip_Time<=0 的資料有 7278 筆\n",
      "Trip_Distance<=0 的資料有 60013 筆\n",
      "Fare_Amt<0 的資料有 60013 筆\n",
      "df0.Extra<0 的資料有 2847 筆\n",
      "Tip_Amt<0 的資料有 67 筆\n",
      "\n",
      "Total: 75937\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Trip_Time<=0\n",
    "#Trip_Distance<=0\n",
    "#'Fare_Amt', 'Extra', 'Tip_Amt'<0\n",
    "#Trip_Distance<True_Distance\n",
    "#True_Distance>=5\n",
    "for i in range(len(t)):\n",
    "    print(files[i])\n",
    "    tttmp=0\n",
    "    tmp0 = t[i].filter(t[i].Trip_Time<=0).count()\n",
    "    tmp1 = t[i].filter(t[i].Trip_Distance<=0).count()\n",
    "    tmp2 = t[i].filter(t[i].Fare_Amt<0).count()\n",
    "    tmp3 = t[i].filter(t[i].Extra<0).count()\n",
    "    tmp4 = t[i].filter(t[i].Tip_Amt<0).count()\n",
    "    if tmp0>0 :\n",
    "        tttmp+=tmp0\n",
    "        print('Trip_Time<=0 的資料有',tmp0,'筆')\n",
    "    if tmp1>0 :\n",
    "        tttmp+=tmp1\n",
    "        print('Trip_Distance<=0 的資料有',tmp1,'筆')\n",
    "    if tmp2>0 :\n",
    "        tttmp+=tmp2\n",
    "        print('Fare_Amt<0 的資料有',tmp1,'筆')\n",
    "    if tmp3>0 :\n",
    "        tttmp+=tmp3\n",
    "        print('df0.Extra<0 的資料有',tmp3,'筆')\n",
    "    if tmp4>0 :\n",
    "        tttmp+=tmp4\n",
    "        print('Tip_Amt<0 的資料有',tmp4,'筆')\n",
    "        \n",
    "    if 'True_Distance' in t[i].columns:\n",
    "        tt0 = t[i].filter(t[i].Trip_Distance<=t[i].True_Distance).count()\n",
    "        if tt0>0 :\n",
    "            tttmp+=tt0\n",
    "            print('Trip_Distance<=True_Distance 的資料有',tt0,'筆')\n",
    "        tt = t[i].filter(t[i].True_Distance>=5).count()\n",
    "        if tt>0 :\n",
    "            tttmp+=tt\n",
    "            print('True_Distance>=5 的資料有',tt,'筆')\n",
    "    print()\n",
    "    print('Total:',tttmp)\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7255409 18\n",
      "61355211 18\n",
      "11581590 18\n",
      "112704296 18\n",
      "782611 18\n",
      "760605 18\n",
      "826456 18\n",
      "789393 18\n",
      "785784 18\n",
      "729533 18\n",
      "8700826 18\n",
      "8436063 18\n",
      "9364906 18\n",
      "9243415 18\n",
      "9160205 18\n",
      "8648906 18\n"
     ]
    }
   ],
   "source": [
    "#Handle nonsense values\n",
    "for j in range(0,len(t)):\n",
    "    t[j]=t[j].filter(t[j]['Trip_Time']>0)\n",
    "    t[j]=t[j].filter(t[j].Trip_Distance>0)\n",
    "    t[j]=t[j].filter(t[j].Fare_Amt>=0)\n",
    "    t[j]=t[j].filter(t[j].Extra>=0)\n",
    "    t[j]=t[j].filter(t[j].Tip_Amt>=0)\n",
    "    if 'True_Distance' in t[j].columns:\n",
    "        t[j]=t[j].filter(t[j].True_Distance<5)\n",
    "        t[j]=t[j].filter(t[j].Trip_Distance>t[j].True_Distance)\n",
    "for j in range(0,len(t)):        \n",
    "    print(t[j].count(),len(t[j].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking time value that make no logical sense\n",
    "for i in range(len(t)): \n",
    "    tmp1 = t[i].filter(df.PU_Month<0).count() + t[i].filter(df.PU_Month>12).count()\n",
    "    tmp2 = t[i].filter(df.PU_Day<0).count() + t[i].filter(df.PU_Day>31).count()\n",
    "    tmp3 = t[i].filter(df.PU_Minute<0).count() + t[i].filter(df.PU_Minute>60).count()\n",
    "    tmp4 = t[i].filter(df.PU_Second<0).count() + t[i].filter(df.PU_Second>60).count()\n",
    "    tmp5 = t[i].filter(df.PU_WeekDay<1).count() + t[i].filter(df.PU_WeekDay>7).count()\n",
    "    tmp6 = t[i].filter(df['PU_Year'] >= 2018) + t[i].filter(df['PU_Year']<=2016)\n",
    "    tmp7 = t[i].filter(df['Speed']>200)\n",
    "print(tmp1,tmp2,tmp3,tmp4,tmp5,tmp6,tmp7)\n",
    "\n",
    "# Get rid of nonse time value\n",
    "for i in range(len(t)): \n",
    "    t[i] = t[i].filter(df['PU_Year']<=2018).filter(df['PU_Year']>=2016)\n",
    "    t[i] = t[i].filter(df['Speed']<200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all the dataframes into one\n",
    "After the process of data cleaning and feature engineering, all dataframes were combine to one for the sake of convenience whem manipulating dataframe. But before this, the columns of all dataframes should be checked if they were in the same order. If not, the orders should be rearranged, otherwise that might cause prblem in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First checking the schemas and the orders of all the data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n",
      "root\n",
      " |-- PU_Time: timestamp (nullable = true)\n",
      " |-- DO_Time: timestamp (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Rate_Code: integer (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- Extra: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Trip_Time: long (nullable = true)\n",
      " |-- PU_Year: integer (nullable = true)\n",
      " |-- PU_Month: integer (nullable = true)\n",
      " |-- PU_Day: integer (nullable = true)\n",
      " |-- PU_Hour: integer (nullable = true)\n",
      " |-- PU_Minute: integer (nullable = true)\n",
      " |-- PU_Second: integer (nullable = true)\n",
      " |-- PU_WeekDay: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(t)):\n",
    "    print(t[i].printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second unify the Order of columns in every dataframe**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(t)):\n",
    "    t[i]=t[i].select('PU_Time','DO_Time','Rate_Code','Trip_Distance','Fare_Amt','Extra','Tip_Amt','PULocationID','DOLocationID','Trip_Time','PU_Year','PU_Month','PU_Day','PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then double check the orders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "['PU_Time', 'DO_Time', 'Rate_Code', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PULocationID', 'DOLocationID', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(t)):\n",
    "    print(t[i].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally all dataframes were combined to one using union function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t[1:]:\n",
    "    t[0]=t[0].union(i)\n",
    "df=t[0]\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the schema of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn('PU_WeekDay',df['PU_WeekDay'].cast('integer'))\n",
    "df=df.withColumn('PU_Hour',df['PU_Hour'].cast('integer'))\n",
    "df=df.withColumn('Rate_Code',df['Rate_Code'].cast('integer'))\n",
    "df=df.withColumn('Trip_Distance',df['Trip_Distance'].cast('double'))\n",
    "df=df.withColumn('Fare_Amt',df['Fare_Amt'].cast('double'))\n",
    "df=df.withColumn('Extra',df['Extra'].cast('double'))\n",
    "df=df.withColumn('Tip_Amt',df['Tip_Amt'].cast('double'))\n",
    "df=df.withColumn('PULocationID',df['PULocationID'].cast('integer'))\n",
    "df=df.withColumn('DOLocationID',df['DOLocationID'].cast('integer'))\n",
    "df=df.withColumn('Trip_Time',df['Trip_Time'].cast('double'))\n",
    "df=df.withColumn('PU_Month',df['PU_Month'].cast('integer'))\n",
    "df=df.withColumn('PU_Year',df['PU_Year'].cast('integer'))\n",
    "df=df.withColumn('PU_Day',df['PU_Day'].cast('integer'))\n",
    "df=df.withColumn('PU_Minute',df['PU_Minute'].cast('integer'))\n",
    "df=df.withColumn('PU_Second',df['PU_Second'].cast('integer'))\n",
    "df=df.withColumn('Speed',df['Speed'].cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out PU_Time and DO_Time that was out of date(2018/6/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = \"^(2018)(-)(0[7-9]|1[012])\"\n",
    "\n",
    "df.filter(~df[\"PU_Time\"].rlike(expr)).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the output dataset\n",
    "After the combination process, some basic description were made to see the full picture of processed dataset.\n",
    "In the processed dataset, There were:\n",
    "1. **251125209 rows in total**\n",
    "1. **18 columns** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251125209"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.coalesce(1).write.csv(\"/user/hadoop/NYCTaxi/16-18/final_df\",header=True,sep=',')\n",
    "df_final.write.csv(\"/user/hadoop/NYCTaxi/16-18/final_df\",header=True,sep=',',timestampFormat='yyyy-MM-dd HH:mm:ss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
