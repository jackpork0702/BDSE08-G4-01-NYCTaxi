{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#init\n",
    "#set path\n",
    "from os import listdir #os no need to install\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sqrt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types\n",
    "\n",
    "mypath = \"D:/Download/NYtaxi/headdata\" #your dir\n",
    "files = listdir(mypath)\n",
    "df = ['PU_Time','DO_Time','Trip_Distance','Rate_Code','PU_Lon','PU_Lat','DO_Lon','DO_Lat','Fare_Amt','Extra','Tip_Amt','PULocationID','DOLocationID']\n",
    "\n",
    "PU_Time = ('Pickup_date','Pickup_DateTime','pickup_datetime','lpep_pickup_datetime','Trip_Pickup_DateTime','tpep_pickup_datetime')\n",
    "DO_Time = ('DropOff_datetime','dropoff_datetime','Lpep_dropoff_datetime','lpep_dropoff_datetime','Trip_Dropoff_DateTime','tpep_dropoff_datetime')\n",
    "Trip_Distance = ('Trip_distance','trip_distance','Trip_Distance')\n",
    "Rate_Code = ('rate_code','RateCodeID','Rate_Code','RatecodeID')\n",
    "PU_Lon = ('Pickup_longitude','Start_Lon','pickup_longitude')\n",
    "PU_Lat = ('Pickup_latitude','Start_Lat','pickup_latitude')\n",
    "DO_Lon = ('Dropoff_longitude','End_Lon','dropoff_longitude')\n",
    "DO_Lat = ('Dropoff_latitude','End_Lat','dropoff_latitude')\n",
    "Fare_Amt = ('Fare_amount','fare_amount','Fare_Amt')\n",
    "Extra = ('Extra','extra','surcharge')\n",
    "Tip_Amt = ('Tip_amount','tip_amount','Tip_Amt')\n",
    "PULocationID = ('PULocationID')\n",
    "DOLocationID = ('DOLocationID')\n",
    "\n",
    "\n",
    "cols = [PU_Time,DO_Time,Trip_Distance,Rate_Code,PU_Lon,PU_Lat,DO_Lon,DO_Lat,Fare_Amt,Extra,Tip_Amt,PULocationID,DOLocationID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目錄下的檔案有:\n",
      "2009_Yellow_head_50K_y.csv\n",
      "2010_Yellow_head_50K_y.csv\n",
      "2011_Yellow_head_50K_y.csv\n",
      "2012_Yellow_head_50K_y.csv\n",
      "2013_Green_head_50K_x.csv\n",
      "2013_Yellow_head_50K.csv\n",
      "2014_Green_head_50K.csv\n",
      "2014_Yellow_head_50K_x.csv\n",
      "2015_0106_Yellow_head_50K.csv\n",
      "2015_Green_head_50K.csv\n",
      "2016_Green_head_50K.csv\n",
      "2016_Yellow_head_50K.csv\n",
      "2017_Green_head_50K.csv\n",
      "2017_Yellow_head_50K.csv\n",
      "第一個檔案的原始欄位\n",
      "49999 18\n",
      "---------\n",
      "[('vendor_name', 'string'), ('Trip_Pickup_DateTime', 'timestamp'), ('Trip_Dropoff_DateTime', 'timestamp'), ('Passenger_Count', 'int'), ('Trip_Distance', 'double'), ('Start_Lon', 'double'), ('Start_Lat', 'double'), ('Rate_Code', 'string'), ('store_and_forward', 'int'), ('End_Lon', 'double'), ('End_Lat', 'double'), ('Payment_Type', 'string'), ('Fare_Amt', 'double'), ('surcharge', 'double'), ('mta_tax', 'string'), ('Tip_Amt', 'double'), ('Tolls_Amt', 'double'), ('Total_Amt', 'double')]\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#infile\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"moz\")\\\n",
    "        .getOrCreate()\n",
    "print('目錄下的檔案有:')\n",
    "t=[]\n",
    "for  f in files:\n",
    "    print(f)\n",
    "    fullpath = mypath+'/'+f\n",
    "    t += [spark.read.csv(fullpath,sep = ',',header = True,inferSchema = True).limit(49999)]\n",
    "df0=t[0]\n",
    "print('第一個檔案的原始欄位')\n",
    "print(df0.count(),len(df0.columns))\n",
    "print('---------')\n",
    "print(df0.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一個檔案的修正欄位\n",
      "['vendor_name', 'PU_Time', 'DO_Time', 'Passenger_Count', 'Trip_Distance', 'PU_Lon', 'PU_Lat', 'Rate_Code', 'store_and_forward', 'DO_Lon', 'DO_Lat', 'Payment_Type', 'Fare_Amt', 'Extra', 'mta_tax', 'Tip_Amt', 'Tolls_Amt', 'Total_Amt']\n",
      "Wall time: 530 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#change columns name\n",
    "for j in range(0,len(t)):\n",
    "    for w in range(0,len(t[j].columns)):\n",
    "        for i in range(0,len(cols)):\n",
    "            for k in range(0,len(cols[i])):\n",
    "                if t[j].columns[w] == cols[i][k]:\n",
    "                    t[j]=t[j].withColumnRenamed(t[j].columns[w],df[i])\n",
    "print('第一個檔案的修正欄位')\n",
    "print(t[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一個檔案的刪除後欄位\n",
      "['PU_Time', 'DO_Time', 'Trip_Distance', 'PU_Lon', 'PU_Lat', 'Rate_Code', 'DO_Lon', 'DO_Lat', 'Fare_Amt', 'Extra', 'Tip_Amt']\n",
      "每個table的欄位數\n",
      "11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 13, 13, 9, 9, Wall time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Drop useless columns\n",
    "for i in range(len(t)):\n",
    "    for c in t[i].columns:\n",
    "        if c not in df:\n",
    "            t[i] = t[i].drop(c)\n",
    "print('第一個檔案的刪除後欄位')\n",
    "print(t[0].columns)\n",
    "print('每個table的欄位數')\n",
    "for tb in t:\n",
    "    print(len(tb.columns),end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 2009_Yellow_head_50K_y.csv do not have column Rate_Code\n",
      "Table 2009_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2009_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2010_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2010_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2011_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2011_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2012_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2012_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2013_Green_head_50K_x.csv do not have column PULocationID\n",
      "Table 2013_Green_head_50K_x.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2013_Yellow_head_50K.csv do not have column PULocationID\n",
      "Table 2013_Yellow_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2014_Green_head_50K.csv do not have column PULocationID\n",
      "Table 2014_Green_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2014_Yellow_head_50K_x.csv do not have column PULocationID\n",
      "Table 2014_Yellow_head_50K_x.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2015_0106_Yellow_head_50K.csv do not have column PULocationID\n",
      "Table 2015_0106_Yellow_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2015_Green_head_50K.csv do not have column PULocationID\n",
      "Table 2015_Green_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2016_Green_head_50K.csv do not have column PULocationID\n",
      "Table 2016_Green_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2016_Yellow_head_50K.csv do not have column PU_Lon\n",
      "Table 2016_Yellow_head_50K.csv do not have column PU_Lat\n",
      "Table 2016_Yellow_head_50K.csv do not have column DO_Lon\n",
      "Table 2016_Yellow_head_50K.csv do not have column DO_Lat\n",
      "---------------------------------------------\n",
      "Table 2017_Green_head_50K.csv do not have column PU_Lon\n",
      "Table 2017_Green_head_50K.csv do not have column PU_Lat\n",
      "Table 2017_Green_head_50K.csv do not have column DO_Lon\n",
      "Table 2017_Green_head_50K.csv do not have column DO_Lat\n",
      "---------------------------------------------\n",
      "Table 2017_Yellow_head_50K.csv do not have column PU_Lon\n",
      "Table 2017_Yellow_head_50K.csv do not have column PU_Lat\n",
      "Table 2017_Yellow_head_50K.csv do not have column DO_Lon\n",
      "Table 2017_Yellow_head_50K.csv do not have column DO_Lat\n",
      "---------------------------------------------\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Check NA values\n",
    "for i in range(0,len(t)):\n",
    "    for col in df:\n",
    "        if col not in t[i].columns:\n",
    "            print('Table',files[i],'do not have column', col)\n",
    "        else:\n",
    "            tmp=t[i].filter(t[i][col].isNull()).count()\n",
    "            if tmp!=0:\n",
    "                print('In table',files[i],'column',col,'has',tmp,'NA values.')\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Handle NA values\n",
    "\n",
    "#Drop all NA columns\n",
    "for i in range(0,len(t)):\n",
    "    for col in t[i]:\n",
    "        if t[i].filter(col.isNull()).count()==t[i].count():\n",
    "            t[i] = t[i].drop(col)\n",
    "\n",
    "#Drop few NA rows\n",
    "for i in range(0,len(t)):\n",
    "     t[i] = t[i].na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#New Columns\n",
    "\n",
    "\n",
    "# timeDiff = (F.unix_timestamp('EndDateTime')\n",
    "#             - F.unix_timestamp('StartDateTime'))\n",
    "# df = df.withColumn(\"Duration\", timeDiff)\n",
    "\n",
    "#True_Distance\n",
    "for i in range(len(t)):\n",
    "    if 'DO_Lon' in t[i].columns:\n",
    "        t[i] = t[i].withColumn('True_Distance',(t[i].DO_Lon-t[i].PU_Lon)*(t[i].DO_Lon-t[i].PU_Lon)+(t[i].DO_Lat-t[i].PU_Lat)*(t[i].DO_Lat-t[i].PU_Lat))\n",
    "for i in range(len(t)):\n",
    "    if 'True_Distance' in t[i].columns:\n",
    "        t[i] = t[i].withColumn('True_Distance',sqrt(t[i].True_Distance))\n",
    "#Trip_Time\n",
    "for i in range(len(t)):\n",
    "    if 'DO_Time' in t[i].columns:\n",
    "        if i in (4, 6, 9, 10, 11, 12, 13):\n",
    "            tt = F.unix_timestamp(t[i].DO_Time,'MM/dd/yyyy h:mm:ss a')-F.unix_timestamp(t[i].PU_Time,'MM/dd/yyyy h:mm:ss a')\n",
    "            t[i] = t[i].withColumn('Trip_Time', tt) \n",
    "        else:\n",
    "            tt = F.unix_timestamp(t[i].DO_Time)-F.unix_timestamp(t[i].PU_Time)\n",
    "            t[i] = t[i].withColumn('Trip_Time', tt) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PU_Time', 'DO_Time', 'Trip_Distance', 'PU_Lon', 'PU_Lat', 'DO_Lon', 'DO_Lat', 'Fare_Amt', 'Extra', 'Tip_Amt', 'True_Distance', 'Trip_Time', 'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second', 'PU_WeekDay', 'Speed']\n",
      "Row(PU_Time=datetime.datetime(2009, 1, 4, 2, 52), DO_Time=datetime.datetime(2009, 1, 4, 3, 2), Trip_Distance=4.23257472, PU_Lon=-73.991957, PU_Lat=40.721567, DO_Lon=-73.993803, DO_Lat=40.695922, Fare_Amt=8.9, Extra=0.5, Tip_Amt=0.0, True_Distance=0.025711354320608257, Trip_Time=600, PU_Year=2009, PU_Month=1, PU_Day=4, PU_Hour=2, PU_Minute=52, PU_Second=0, PU_WeekDay=1, Speed=25.39544832)\n"
     ]
    }
   ],
   "source": [
    "#PU_Year\n",
    "#PU_Month\n",
    "#PU_Day\n",
    "#PU_Hour\n",
    "#PU_Minute\n",
    "#PU_Second\n",
    "#PU_WeekDay(0:6)\n",
    "#Trip_Distance :miles to km\n",
    "#Speed(km/hr)\n",
    "for i in range(len(t)):\n",
    "    t[i] = t[i].withColumn('PU_Year',F.year(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Month',F.month(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Day',F.dayofmonth(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Hour',F.hour(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Minute',F.minute(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_Second',F.second(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('PU_WeekDay',F.dayofweek(t[i].PU_Time))\n",
    "    t[i] = t[i].withColumn('Trip_Distance',t[i].Trip_Distance*1.609344)\n",
    "    t[i] = t[i].withColumn('Speed',t[i].Trip_Distance*3600/t[i].Trip_Time)\n",
    "print(t[0].columns)\n",
    "print(t[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009_Yellow_head_50K_y.csv\n",
      "Trip_Time<=0 的資料有 1485 筆\n",
      "Trip_Distance<=0 的資料有 403 筆\n",
      "Trip_Distance<=True_Distance 的資料有 433 筆\n",
      "True_Distance>=5 的資料有 27 筆\n",
      "\n",
      "Total: 2348\n",
      "---------------------------------\n",
      "2010_Yellow_head_50K_y.csv\n",
      "Trip_Time<=0 的資料有 125 筆\n",
      "Trip_Distance<=0 的資料有 274 筆\n",
      "Trip_Distance<=True_Distance 的資料有 297 筆\n",
      "True_Distance>=5 的資料有 23 筆\n",
      "\n",
      "Total: 719\n",
      "---------------------------------\n",
      "2011_Yellow_head_50K_y.csv\n",
      "Trip_Time<=0 的資料有 33 筆\n",
      "Trip_Distance<=0 的資料有 409 筆\n",
      "Trip_Distance<=True_Distance 的資料有 438 筆\n",
      "True_Distance>=5 的資料有 47 筆\n",
      "\n",
      "Total: 927\n",
      "---------------------------------\n",
      "2012_Yellow_head_50K_y.csv\n",
      "Trip_Time<=0 的資料有 22 筆\n",
      "Trip_Distance<=0 的資料有 251 筆\n",
      "Trip_Distance<=True_Distance 的資料有 308 筆\n",
      "True_Distance>=5 的資料有 66 筆\n",
      "\n",
      "Total: 647\n",
      "---------------------------------\n",
      "2013_Green_head_50K_x.csv\n",
      "Trip_Time<=0 的資料有 61 筆\n",
      "Trip_Distance<=0 的資料有 1493 筆\n",
      "Trip_Distance<=True_Distance 的資料有 1543 筆\n",
      "True_Distance>=5 的資料有 108 筆\n",
      "\n",
      "Total: 3205\n",
      "---------------------------------\n",
      "2013_Yellow_head_50K.csv\n",
      "Trip_Time<=0 的資料有 244 筆\n",
      "Trip_Distance<=0 的資料有 236 筆\n",
      "Trip_Distance<=True_Distance 的資料有 321 筆\n",
      "True_Distance>=5 的資料有 115 筆\n",
      "\n",
      "Total: 916\n",
      "---------------------------------\n",
      "2014_Green_head_50K.csv\n",
      "Trip_Time<=0 的資料有 50 筆\n",
      "Trip_Distance<=0 的資料有 996 筆\n",
      "Trip_Distance<=True_Distance 的資料有 1073 筆\n",
      "True_Distance>=5 的資料有 121 筆\n",
      "\n",
      "Total: 2240\n",
      "---------------------------------\n",
      "2014_Yellow_head_50K_x.csv\n",
      "Trip_Time<=0 的資料有 8 筆\n",
      "Trip_Distance<=0 的資料有 185 筆\n",
      "Trip_Distance<=True_Distance 的資料有 269 筆\n",
      "True_Distance>=5 的資料有 84 筆\n",
      "\n",
      "Total: 546\n",
      "---------------------------------\n",
      "2015_0106_Yellow_head_50K.csv\n",
      "Trip_Time<=0 的資料有 63 筆\n",
      "Trip_Distance<=0 的資料有 335 筆\n",
      "Fare_Amt<0 的資料有 335 筆\n",
      "df0.Extra<0 的資料有 9 筆\n",
      "Trip_Distance<=True_Distance 的資料有 450 筆\n",
      "True_Distance>=5 的資料有 185 筆\n",
      "\n",
      "Total: 1051\n",
      "---------------------------------\n",
      "2015_Green_head_50K.csv\n",
      "Trip_Time<=0 的資料有 35 筆\n",
      "Trip_Distance<=0 的資料有 701 筆\n",
      "Fare_Amt<0 的資料有 701 筆\n",
      "df0.Extra<0 的資料有 48 筆\n",
      "Trip_Distance<=True_Distance 的資料有 744 筆\n",
      "True_Distance>=5 的資料有 102 筆\n",
      "\n",
      "Total: 1715\n",
      "---------------------------------\n",
      "2016_Green_head_50K.csv\n",
      "Trip_Time<=0 的資料有 31 筆\n",
      "Trip_Distance<=0 的資料有 643 筆\n",
      "Fare_Amt<0 的資料有 643 筆\n",
      "df0.Extra<0 的資料有 48 筆\n",
      "Tip_Amt<0 的資料有 1 筆\n",
      "Trip_Distance<=True_Distance 的資料有 704 筆\n",
      "True_Distance>=5 的資料有 105 筆\n",
      "\n",
      "Total: 1630\n",
      "---------------------------------\n",
      "2016_Yellow_head_50K.csv\n",
      "Trip_Time<=0 的資料有 59 筆\n",
      "Trip_Distance<=0 的資料有 294 筆\n",
      "Fare_Amt<0 的資料有 294 筆\n",
      "df0.Extra<0 的資料有 8 筆\n",
      "\n",
      "Total: 380\n",
      "---------------------------------\n",
      "2017_Green_head_50K.csv\n",
      "Trip_Time<=0 的資料有 34 筆\n",
      "Trip_Distance<=0 的資料有 621 筆\n",
      "Fare_Amt<0 的資料有 621 筆\n",
      "df0.Extra<0 的資料有 64 筆\n",
      "Tip_Amt<0 的資料有 2 筆\n",
      "\n",
      "Total: 829\n",
      "---------------------------------\n",
      "2017_Yellow_head_50K.csv\n",
      "Trip_Time<=0 的資料有 31 筆\n",
      "Trip_Distance<=0 的資料有 393 筆\n",
      "Fare_Amt<0 的資料有 393 筆\n",
      "df0.Extra<0 的資料有 20 筆\n",
      "\n",
      "Total: 467\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Trip_Time<=0\n",
    "#Trip_Distance<=0\n",
    "#'Fare_Amt', 'Extra', 'Tip_Amt'<0\n",
    "#Trip_Distance<True_Distance\n",
    "#True_Distance>=5\n",
    "for i in range(len(t)):\n",
    "    print(files[i])\n",
    "    tttmp=0\n",
    "    tmp0 = t[i].filter(t[i].Trip_Time<=0).count()\n",
    "    tmp1 = t[i].filter(t[i].Trip_Distance<=0).count()\n",
    "    tmp2 = t[i].filter(t[i].Fare_Amt<0).count()\n",
    "    tmp3 = t[i].filter(t[i].Extra<0).count()\n",
    "    tmp4 = t[i].filter(t[i].Tip_Amt<0).count()\n",
    "    if tmp0>0 :\n",
    "        tttmp+=tmp0\n",
    "        print('Trip_Time<=0 的資料有',tmp0,'筆')\n",
    "    if tmp1>0 :\n",
    "        tttmp+=tmp1\n",
    "        print('Trip_Distance<=0 的資料有',tmp1,'筆')\n",
    "    if tmp2>0 :\n",
    "        tttmp+=tmp2\n",
    "        print('Fare_Amt<0 的資料有',tmp1,'筆')\n",
    "    if tmp3>0 :\n",
    "        tttmp+=tmp3\n",
    "        print('df0.Extra<0 的資料有',tmp3,'筆')\n",
    "    if tmp4>0 :\n",
    "        tttmp+=tmp4\n",
    "        print('Tip_Amt<0 的資料有',tmp4,'筆')\n",
    "        \n",
    "    if 'True_Distance' in t[i].columns:\n",
    "        tt0 = t[i].filter(t[i].Trip_Distance<=t[i].True_Distance).count()\n",
    "        if tt0>0 :\n",
    "            tttmp+=tt0\n",
    "            print('Trip_Distance<=True_Distance 的資料有',tt0,'筆')\n",
    "        tt = t[i].filter(t[i].True_Distance>=5).count()\n",
    "        if tt>0 :\n",
    "            tttmp+=tt\n",
    "            print('True_Distance>=5 的資料有',tt,'筆')\n",
    "    print()\n",
    "    print('Total:',tttmp)\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48283 20\n",
      "49635 21\n",
      "49554 21\n",
      "49686 21\n",
      "48452 21\n",
      "49611 21\n",
      "48926 21\n",
      "49725 21\n",
      "49535 21\n",
      "49184 21\n",
      "49208 21\n",
      "49687 18\n",
      "49286 18\n",
      "49583 18\n"
     ]
    }
   ],
   "source": [
    "#Handle nonsense values\n",
    "for j in range(0,len(t)):\n",
    "    t[j]=t[j].filter(t[j]['Trip_Time']>0)\n",
    "    t[j]=t[j].filter(t[j].Trip_Distance>0)\n",
    "    t[j]=t[j].filter(t[j].Fare_Amt>=0)\n",
    "    t[j]=t[j].filter(t[j].Extra>=0)\n",
    "    t[j]=t[j].filter(t[j].Tip_Amt>=0)\n",
    "    if 'True_Distance' in t[j].columns:\n",
    "        t[j]=t[j].filter(t[j].True_Distance<5)\n",
    "        t[j]=t[j].filter(t[j].Trip_Distance>t[j].True_Distance)\n",
    "for j in range(0,len(t)):        \n",
    "    print(t[j].count(),len(t[j].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.58065664, 27.0369792]\n",
      "[5.7, 10.9]\n",
      "[0.0, 0.5]\n",
      "[0.0, 0.0]\n",
      "[14.966899200000002, 25.72908409199048]\n",
      "[5.3, 10.5]\n",
      "[0.0, 0.5]\n",
      "[0.0, 1.0]\n",
      "[12.573839599332223, 22.7498890052356]\n",
      "[5.7, 10.9]\n",
      "[0.0, 0.5]\n",
      "[0.0, 1.11]\n",
      "[14.148988380462724, 24.97952578581363]\n",
      "[5.7, 10.9]\n",
      "[0.0, 0.5]\n",
      "[0.0, 1.62]\n",
      "[16.031890285714287, 26.325297917710202]\n",
      "[6.5, 15.5]\n",
      "[0.0, 0.5]\n",
      "[0.0, 1.1]\n",
      "[17.743017599999998, 29.78524356923077]\n",
      "[6.0, 13.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 1.7]\n",
      "[16.428086200378072, 27.56999918422842]\n",
      "[6.5, 15.0]\n",
      "[0.0, 0.5]\n",
      "[0.0, 0.0]\n",
      "[15.836824783599088, 27.009969230769233]\n",
      "[7.0, 14.5]\n",
      "[0.5, 0.5]\n",
      "[1.25, 2.9]\n",
      "[16.037753356401385, 26.277841555075597]\n",
      "[6.5, 15.5]\n",
      "[0.5, 0.5]\n",
      "[0.0, 2.3]\n",
      "[15.122057814029366, 24.127554172323762]\n",
      "[6.5, 15.5]\n",
      "[0.0, 0.5]\n",
      "[0.0, 2.0]\n",
      "[17.121333689227836, 27.432000000000002]\n",
      "[7.0, 16.5]\n",
      "[0.0, 0.5]\n",
      "[0.0, 1.96]\n",
      "[11.798594917933132, 22.51556155450237]\n",
      "[6.5, 15.0]\n",
      "[0.0, 0.5]\n",
      "[0.0, 2.36]\n",
      "[17.2985411943128, 27.090624000000005]\n",
      "[6.5, 15.0]\n",
      "[0.0, 0.5]\n",
      "[0.0, 1.76]\n",
      "[16.92946285714286, 28.090368]\n",
      "[6.5, 16.0]\n",
      "[0.5, 0.5]\n",
      "[0.0, 2.66]\n"
     ]
    }
   ],
   "source": [
    "#Check Outliers\n",
    "#Speed ,Fare Outliers\n",
    "needCheck=['Speed','Fare_Amt','Extra','Tip_Amt']\n",
    "def detect_outlier(df,cols):\n",
    "    quan = df.approxQuantile(col=cols,probabilities=[0.25,0.75],relativeError=0)\n",
    "    print(quan[1])\n",
    "#     tmp = df.filter(df[cols]<quan[0]).count()+df.filter(df[cols]>quan[1]).count()\n",
    "#     if tmp!=0:\n",
    "#         print(col,\"的outliers 有\",tmp,\"筆\")\n",
    "for i in range(len(t)):\n",
    "    for j in needCheck:\n",
    "#         detect_outlier(t[i],j)\n",
    "        quan = t[i].approxQuantile(col=j,probabilities=[0.25,0.75],relativeError=0)\n",
    "        print(quan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = t[4]\n",
    "# print(df0.approxQuantile(col='Fare_Amt',probabilities=[0.25,0.5,0.75],relativeError=0))\n",
    "# type(df0.Speed)\n",
    "# type(df0.select('Speed').collect())\n",
    "print(df0.count(),len(df0.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
