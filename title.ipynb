{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#init\n",
    "#set path\n",
    "from os import listdir #os no need to install\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "mypath = \"D:/Download/NYtaxi/headdata\" #your dir\n",
    "files = listdir(mypath)\n",
    "df = pd.Series([\"PU_Time\",\"DO_Time\",\"Trip_Distance\",\"Rate_Code\",\"PU_Lon\",\"PU_Lat\",\"DO_Lon\",\"DO_Lat\",\"Fare_Amt\",\"Extra\",\"Tip_Amt\",\"PULocationID\",\"DOLocationID\"])\n",
    "\n",
    "PU_Time = pd.Series(['Pickup_date','Pickup_DateTime','pickup_datetime','lpep_pickup_datetime','Trip_Pickup_DateTime','tpep_pickup_datetime'])\n",
    "DO_Time = pd.Series(['DropOff_datetime','dropoff_datetime','Lpep_dropoff_datetime','lpep_dropoff_datetime','Trip_Dropoff_DateTime','tpep_dropoff_datetime'])\n",
    "Trip_Distance = pd.Series(['Trip_distance','trip_distance','Trip_Distance'])\n",
    "Rate_Code = pd.Series(['rate_code','RateCodeID','Rate_Code','RatecodeID'])\n",
    "PU_Lon = pd.Series(['Pickup_longitude','Start_Lon','pickup_longitude'])\n",
    "\n",
    "PU_Lat = pd.Series(['Pickup_latitude','Start_Lat','pickup_latitude'])\n",
    "DO_Lon = pd.Series(['Dropoff_longitude','End_Lon','dropoff_longitude'])\n",
    "DO_Lat = pd.Series(['Dropoff_latitude','End_Lat','dropoff_latitude'])\n",
    "Fare_Amt = pd.Series(['Fare_amount','fare_amount','Fare_Amt'])\n",
    "Extra = pd.Series(['Extra','extra','surcharge'])\n",
    "\n",
    "Tip_Amt = pd.Series(['Tip_amount','tip_amount','Tip_Amt'])\n",
    "PULocationID = pd.Series('PULocationID')\n",
    "DOLocationID = pd.Series('DOLocationID')\n",
    "\n",
    "cols = pd.Series([PU_Time,DO_Time,Trip_Distance,Rate_Code,PU_Lon,PU_Lat,DO_Lon,DO_Lat,Fare_Amt,Extra,Tip_Amt,PULocationID,DOLocationID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目錄下的檔案有:\n",
      "2009_Yellow_head_50K_y.csv\n",
      "2010_Yellow_head_50K_y.csv\n",
      "2011_Yellow_head_50K_y.csv\n",
      "2012_Yellow_head_50K_y.csv\n",
      "2013_Green_head_50K_x.csv\n",
      "2013_Yellow_head_50K.csv\n",
      "2014_Green_head_50K.csv\n",
      "2014_Yellow_head_50K_x.csv\n",
      "2015_0106_Yellow_head_50K.csv\n",
      "2015_Green_head_50K.csv\n",
      "2016_Green_head_50K.csv\n",
      "2016_Yellow_head_50K.csv\n",
      "2017_Green_head_50K.csv\n",
      "2017_Yellow_head_50K.csv\n",
      "第一個檔案的原始欄位\n",
      "Index(['vendor_name', 'Trip_Pickup_DateTime', 'Trip_Dropoff_DateTime',\n",
      "       'Passenger_Count', 'Trip_Distance', 'Start_Lon', 'Start_Lat',\n",
      "       'Rate_Code', 'store_and_forward', 'End_Lon', 'End_Lat', 'Payment_Type',\n",
      "       'Fare_Amt', 'surcharge', 'mta_tax', 'Tip_Amt', 'Tolls_Amt',\n",
      "       'Total_Amt'],\n",
      "      dtype='object')\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#infile\n",
    "#set nrows\n",
    "print('目錄下的檔案有:')\n",
    "t=[]\n",
    "for  f in files:\n",
    "    print(f)\n",
    "    fullpath = mypath+'/'+f\n",
    "    t += [pd.read_csv(fullpath,nrows=49999)]\n",
    "\n",
    "print('第一個檔案的原始欄位')\n",
    "print(t[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一個檔案的修正欄位\n",
      "Index(['vendor_name', 'PU_Time', 'DO_Time', 'Passenger_Count', 'Trip_Distance',\n",
      "       'PU_Lon', 'PU_Lat', 'Rate_Code', 'store_and_forward', 'DO_Lon',\n",
      "       'DO_Lat', 'Payment_Type', 'Fare_Amt', 'Extra', 'mta_tax', 'Tip_Amt',\n",
      "       'Tolls_Amt', 'Total_Amt'],\n",
      "      dtype='object')\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#change columns name\n",
    "for j in range(0,len(t)):\n",
    "    for w in range(0,len(t[j].columns)):\n",
    "        for i in range(0,len(cols)):\n",
    "            for k in range(0,len(cols[i])):\n",
    "                if t[j].columns[w] == cols[i][k]:\n",
    "                    t[j].rename(columns= {t[j].columns[w]:df[i]},inplace=True)\n",
    "print('第一個檔案的修正欄位')\n",
    "print(t[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一個檔案的刪除後欄位\n",
      "Index(['PU_Time', 'DO_Time', 'Trip_Distance', 'PU_Lon', 'PU_Lat', 'Rate_Code',\n",
      "       'DO_Lon', 'DO_Lat', 'Fare_Amt', 'Extra', 'Tip_Amt'],\n",
      "      dtype='object')\n",
      "Wall time: 448 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Drop useless columns\n",
    "for tables in t:\n",
    "    for c in tables.columns:\n",
    "        if sum(c == df)!=1:\n",
    "            tables.drop(columns=c,axis=1,inplace=True)\n",
    "print('第一個檔案的刪除後欄位')\n",
    "print(t[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bdf = pd.concat(t,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Format Time\n",
    "for j in range(0,len(t)):\n",
    "    t[j]['PU_Time'] = pd.to_datetime(t[j].PU_Time)\n",
    "    t[j]['DO_Time'] = pd.to_datetime(t[j].DO_Time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In table 2009_Yellow_head_50K_y.csv column Rate_Code has 49999 NA values.\n",
      "Table 2009_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2009_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2010_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2010_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2011_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2011_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2012_Yellow_head_50K_y.csv do not have column PULocationID\n",
      "Table 2012_Yellow_head_50K_y.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2013_Green_head_50K_x.csv do not have column PULocationID\n",
      "Table 2013_Green_head_50K_x.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2013_Yellow_head_50K.csv do not have column PULocationID\n",
      "Table 2013_Yellow_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2014_Green_head_50K.csv do not have column PULocationID\n",
      "Table 2014_Green_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "In table 2014_Yellow_head_50K_x.csv column DO_Lon has 4 NA values.\n",
      "In table 2014_Yellow_head_50K_x.csv column DO_Lat has 4 NA values.\n",
      "Table 2014_Yellow_head_50K_x.csv do not have column PULocationID\n",
      "Table 2014_Yellow_head_50K_x.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2015_0106_Yellow_head_50K.csv do not have column PULocationID\n",
      "Table 2015_0106_Yellow_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "Table 2015_Green_head_50K.csv do not have column PULocationID\n",
      "Table 2015_Green_head_50K.csv do not have column DOLocationID\n",
      "---------------------------------------------\n",
      "In table 2016_Green_head_50K.csv column PULocationID has 49999 NA values.\n",
      "In table 2016_Green_head_50K.csv column DOLocationID has 49999 NA values.\n",
      "---------------------------------------------\n",
      "In table 2016_Yellow_head_50K.csv column PU_Lon has 49999 NA values.\n",
      "In table 2016_Yellow_head_50K.csv column PU_Lat has 49999 NA values.\n",
      "In table 2016_Yellow_head_50K.csv column DO_Lon has 49999 NA values.\n",
      "In table 2016_Yellow_head_50K.csv column DO_Lat has 49999 NA values.\n",
      "---------------------------------------------\n",
      "Table 2017_Green_head_50K.csv do not have column PU_Lon\n",
      "Table 2017_Green_head_50K.csv do not have column PU_Lat\n",
      "Table 2017_Green_head_50K.csv do not have column DO_Lon\n",
      "Table 2017_Green_head_50K.csv do not have column DO_Lat\n",
      "---------------------------------------------\n",
      "Table 2017_Yellow_head_50K.csv do not have column PU_Lon\n",
      "Table 2017_Yellow_head_50K.csv do not have column PU_Lat\n",
      "Table 2017_Yellow_head_50K.csv do not have column DO_Lon\n",
      "Table 2017_Yellow_head_50K.csv do not have column DO_Lat\n",
      "---------------------------------------------\n",
      "Wall time: 94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Check NA values\n",
    "for i in range(0,len(t)):\n",
    "    tmp=0\n",
    "    for col in df:\n",
    "        if col not in t[i].columns:\n",
    "            print('Table',files[i],'do not have column', col)\n",
    "        else:\n",
    "            if t[i][col].isnull().any().any():\n",
    "                print('In table',files[i],'column',col,'has',t[i][col].isnull().sum(),'NA values.')\n",
    "                tmp=1\n",
    "#             else:\n",
    "#                 print('In table',files[i],'column',col,'is clear.')\n",
    "#     if tmp==0:\n",
    "#         print('Table',files[i],'is clear.')\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 220 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Handle NA values\n",
    "\n",
    "#Drop all NA columns\n",
    "for tables in t:\n",
    "    for col in tables:\n",
    "        if tables[col].isnull().sum()==len(tables[col]):\n",
    "            tables.drop(columns=col,axis=1,inplace=True)\n",
    "#Drop few NA rows\n",
    "for tables in t:\n",
    "    tables=tables.dropna()\n",
    "#可以再跑上一格Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#New Columns#take longer than forever\n",
    "\n",
    "#True_Distance\n",
    "for tables in t:\n",
    "    if 'DO_Lon' in tables and 'PU_Lon' in tables:\n",
    "        tables['True_Distance']=((tables['DO_Lon']-tables['PU_Lon'])*(tables['DO_Lon']-tables['PU_Lon']))+((tables['DO_Lat']-tables['PU_Lat'])*(tables['DO_Lat']-tables['PU_Lat']))\n",
    "\n",
    "for tables in t:\n",
    "    if 'True_Distance' in tables:\n",
    "        for rows in tables['True_Distance']:\n",
    "            rows = math.sqrt(rows)\n",
    "#Trip_Time\n",
    "for tables in t:\n",
    "    tables['Trip_Time']=tables['DO_Time']-tables['PU_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一個檔案最終欄位名稱: Index(['PU_Time', 'DO_Time', 'Trip_Distance', 'PU_Lon', 'PU_Lat', 'DO_Lon',\n",
      "       'DO_Lat', 'Fare_Amt', 'Extra', 'Tip_Amt', 'True_Distance', 'Trip_Time',\n",
      "       'PU_Year', 'PU_Month', 'PU_Day', 'PU_Hour', 'PU_Minute', 'PU_Second',\n",
      "       'PU_WeekDay', 'Speed'],\n",
      "      dtype='object')\n",
      "所有Table欄位數:\n",
      "(49999, 20)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 21)\n",
      "(49999, 18)\n",
      "(49999, 18)\n",
      "(49999, 18)\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PU_Year\n",
    "#PU_Month\n",
    "#PU_Day\n",
    "#PU_Hour\n",
    "#PU_Minute\n",
    "#PU_Second\n",
    "#PU_WeekDay(0:6)\n",
    "#Trip_Distance :miles to km\n",
    "#Speed(km/hr)\n",
    "\n",
    "for j in range(0,len(t)):\n",
    "    tmp=None\n",
    "    tmp0=[]\n",
    "    tmp1=[]\n",
    "    tmp2=[]\n",
    "    tmp3=[]\n",
    "    tmp4=[]\n",
    "    tmp5=[]\n",
    "    tmp6=[]\n",
    "    tmp7=[]\n",
    "    spd=[]\n",
    "    for i,row in t[j].iterrows():\n",
    "        tmp=row.PU_Time\n",
    "        tmp0+=[tmp.year]\n",
    "        tmp1+=[tmp.month]\n",
    "        tmp2+=[tmp.day]\n",
    "        tmp3+=[tmp.hour]\n",
    "        tmp4+=[tmp.minute]\n",
    "        tmp5+=[tmp.second]\n",
    "        tmp6+=[tmp.weekday()]\n",
    "        #Miles to km\n",
    "        tmp7+=[row.Trip_Distance*1.609344]\n",
    "        if row.Trip_Time.total_seconds() != 0:\n",
    "            spd+=[(row.Trip_Distance)*3600/row.Trip_Time.total_seconds()]\n",
    "        else:\n",
    "            spd+=[0]\n",
    "    t[j]=t[j].assign(PU_Year=tmp0)\n",
    "    t[j]=t[j].assign(PU_Month=tmp1)\n",
    "    t[j]=t[j].assign(PU_Day=tmp2)\n",
    "    t[j]=t[j].assign(PU_Hour=tmp3)\n",
    "    t[j]=t[j].assign(PU_Minute=tmp4)\n",
    "    t[j]=t[j].assign(PU_Second=tmp5)\n",
    "    t[j]=t[j].assign(PU_WeekDay=tmp6)\n",
    "    t[j]=t[j].assign(Trip_Distance=tmp7)\n",
    "    t[j]['Trip_Distance']=tmp7\n",
    "    t[j]=t[j].assign(Speed=spd)\n",
    "print('第一個檔案最終欄位名稱:',t[0].columns)\n",
    "print('所有Table欄位數:')\n",
    "for table in t:\n",
    "    print(len(table.columns))\n",
    "#counts in hourPU_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009_Yellow_head_50K_y.csv\n",
      "Trip_Time=0 的資料有 1485 筆\n",
      "Trip_Distance=0 的資料有 403 筆\n",
      "True_Distance=0 的資料有 27 筆\n",
      "---------\n",
      "2010_Yellow_head_50K_y.csv\n",
      "Trip_Time=0 的資料有 125 筆\n",
      "Trip_Distance=0 的資料有 274 筆\n",
      "True_Distance=0 的資料有 24 筆\n",
      "---------\n",
      "2011_Yellow_head_50K_y.csv\n",
      "Trip_Time=0 的資料有 33 筆\n",
      "Trip_Distance=0 的資料有 409 筆\n",
      "True_Distance=0 的資料有 47 筆\n",
      "---------\n",
      "2012_Yellow_head_50K_y.csv\n",
      "Trip_Time=0 的資料有 22 筆\n",
      "Trip_Distance=0 的資料有 251 筆\n",
      "True_Distance=0 的資料有 67 筆\n",
      "---------\n",
      "2013_Green_head_50K_x.csv\n",
      "Trip_Time=0 的資料有 61 筆\n",
      "Trip_Distance=0 的資料有 1493 筆\n",
      "True_Distance=0 的資料有 108 筆\n",
      "---------\n",
      "2013_Yellow_head_50K.csv\n",
      "Trip_Time=0 的資料有 244 筆\n",
      "Trip_Distance=0 的資料有 236 筆\n",
      "True_Distance=0 的資料有 116 筆\n",
      "---------\n",
      "2014_Green_head_50K.csv\n",
      "Trip_Time=0 的資料有 50 筆\n",
      "Trip_Distance=0 的資料有 996 筆\n",
      "True_Distance=0 的資料有 121 筆\n",
      "---------\n",
      "2014_Yellow_head_50K_x.csv\n",
      "Trip_Time=0 的資料有 8 筆\n",
      "Trip_Distance=0 的資料有 189 筆\n",
      "True_Distance=0 的資料有 85 筆\n",
      "---------\n",
      "2015_0106_Yellow_head_50K.csv\n",
      "Trip_Time=0 的資料有 63 筆\n",
      "Trip_Distance=0 的資料有 335 筆\n",
      "True_Distance=0 的資料有 185 筆\n",
      "Fare_Amt<0 的資料有 9 筆\n",
      "Extra<0 的資料有 9 筆\n",
      "---------\n",
      "2015_Green_head_50K.csv\n",
      "Trip_Time=0 的資料有 35 筆\n",
      "Trip_Distance=0 的資料有 701 筆\n",
      "True_Distance=0 的資料有 102 筆\n",
      "Fare_Amt<0 的資料有 85 筆\n",
      "Extra<0 的資料有 48 筆\n",
      "---------\n",
      "2016_Green_head_50K.csv\n",
      "Trip_Time=0 的資料有 31 筆\n",
      "Trip_Distance=0 的資料有 643 筆\n",
      "True_Distance=0 的資料有 105 筆\n",
      "Fare_Amt<0 的資料有 98 筆\n",
      "Extra<0 的資料有 48 筆\n",
      "Tip_Amt<0 的資料有 1 筆\n",
      "---------\n",
      "2016_Yellow_head_50K.csv\n",
      "Trip_Time=0 的資料有 59 筆\n",
      "Trip_Distance=0 的資料有 294 筆\n",
      "Fare_Amt<0 的資料有 19 筆\n",
      "Extra<0 的資料有 8 筆\n",
      "---------\n",
      "2017_Green_head_50K.csv\n",
      "Trip_Time=0 的資料有 34 筆\n",
      "Trip_Distance=0 的資料有 621 筆\n",
      "Fare_Amt<0 的資料有 108 筆\n",
      "Extra<0 的資料有 64 筆\n",
      "Tip_Amt<0 的資料有 2 筆\n",
      "---------\n",
      "2017_Yellow_head_50K.csv\n",
      "Trip_Time=0 的資料有 31 筆\n",
      "Trip_Distance=0 的資料有 393 筆\n",
      "Fare_Amt<0 的資料有 23 筆\n",
      "Extra<0 的資料有 20 筆\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "#Check nonsense values\n",
    "\n",
    "from datetime import timedelta\n",
    "#Trip_Time=0\n",
    "#Trip_Distance=0\n",
    "#True_Distance>=5\n",
    "#'Fare_Amt', 'Extra', 'Tip_Amt'<0\n",
    "#Trip_Distance<True_Distance\n",
    "j=0\n",
    "for tables in t:\n",
    "    tmp1=0\n",
    "    tmp2=0 \n",
    "    tmp3=0 \n",
    "    tmp4=0\n",
    "    tmp5=0 \n",
    "    tmp6=0\n",
    "    for i,rows in tables.iterrows():\n",
    "        if rows.Trip_Time.total_seconds()<=0:\n",
    "            tmp1+=1\n",
    "        if rows.Trip_Distance<=0:\n",
    "            tmp2+=1\n",
    "        if 'True_Distance' in tables:\n",
    "            if rows.True_Distance>=5:\n",
    "                tmp3+=1\n",
    "        if rows.Fare_Amt<0:\n",
    "            tmp4+=1\n",
    "        if rows.Extra<0:\n",
    "            tmp5+=1\n",
    "        if rows.Tip_Amt<0:\n",
    "            tmp6+=1\n",
    "    print(files[j])\n",
    "    j+=1\n",
    "    if tmp1 !=0:\n",
    "        print('Trip_Time=0 的資料有',tmp1,'筆')\n",
    "    if tmp2 !=0:\n",
    "        print('Trip_Distance=0 的資料有',tmp2,'筆')\n",
    "    if tmp3 !=0:\n",
    "        print('True_Distance=0 的資料有',tmp3,'筆')\n",
    "    if tmp4 !=0:\n",
    "        print('Fare_Amt<0 的資料有',tmp4,'筆')\n",
    "    if tmp5 !=0:\n",
    "        print('Extra<0 的資料有',tmp5,'筆')\n",
    "    if tmp6 !=0:\n",
    "        print('Tip_Amt<0 的資料有',tmp6,'筆')  \n",
    "    print('---------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48287, 20)\n",
      "(49635, 21)\n",
      "(49554, 21)\n",
      "(49686, 21)\n",
      "(48453, 21)\n",
      "(49611, 21)\n",
      "(48937, 21)\n",
      "(49724, 21)\n",
      "(49535, 21)\n",
      "(49184, 21)\n",
      "(49209, 21)\n",
      "(49687, 18)\n",
      "(49286, 18)\n",
      "(49583, 18)\n"
     ]
    }
   ],
   "source": [
    "#Handle nonsense values\n",
    "for j in range(0,len(t)):\n",
    "    t[j]=t[j][t[j].Trip_Distance>0]\n",
    "    t[j]=t[j][t[j].Fare_Amt>=0]\n",
    "    t[j]=t[j][t[j].Extra>=0]\n",
    "    t[j]=t[j][t[j].Tip_Amt>=0]\n",
    "    if 'True_Distance' in t[j]:\n",
    "        t[j]=t[j][t[j].True_Distance<5]\n",
    "for tables in t:\n",
    "    for i,rows in tables.iterrows():\n",
    "        if rows.Trip_Time.total_seconds()<=0:\n",
    "            tables.drop(index=i,inplace=True)\n",
    "#Check Remain rows\n",
    "for ta in t:\n",
    "    print(ta.shape)\n",
    "#可以再跑上一格Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009_Yellow_head_50K_y.csv\n",
      "Speed 的outliers 有 145 筆\n",
      "Fare_Amt 的outliers 有 1033 筆\n",
      "Tip_Amt 的outliers 有 885 筆\n",
      "2010_Yellow_head_50K_y.csv\n",
      "Speed 的outliers 有 2 筆\n",
      "Fare_Amt 的outliers 有 1093 筆\n",
      "Extra 的outliers 有 110 筆\n",
      "Tip_Amt 的outliers 有 961 筆\n",
      "2011_Yellow_head_50K_y.csv\n",
      "Speed 的outliers 有 21 筆\n",
      "Fare_Amt 的outliers 有 1009 筆\n",
      "Tip_Amt 的outliers 有 894 筆\n",
      "2012_Yellow_head_50K_y.csv\n",
      "Speed 的outliers 有 10 筆\n",
      "Fare_Amt 的outliers 有 1073 筆\n",
      "Tip_Amt 的outliers 有 950 筆\n",
      "2013_Green_head_50K_x.csv\n",
      "Speed 的outliers 有 62 筆\n",
      "Fare_Amt 的outliers 有 889 筆\n",
      "Extra 的outliers 有 6 筆\n",
      "Tip_Amt 的outliers 有 744 筆\n",
      "2013_Yellow_head_50K.csv\n",
      "Speed 的outliers 有 977 筆\n",
      "Fare_Amt 的outliers 有 1375 筆\n",
      "Extra 的outliers 有 50 筆\n",
      "Tip_Amt 的outliers 有 990 筆\n",
      "2014_Green_head_50K.csv\n",
      "Speed 的outliers 有 99 筆\n",
      "Fare_Amt 的outliers 有 925 筆\n",
      "Extra 的outliers 有 5 筆\n",
      "Tip_Amt 的outliers 有 803 筆\n",
      "2014_Yellow_head_50K_x.csv\n",
      "Speed 的outliers 有 23 筆\n",
      "Fare_Amt 的outliers 有 1243 筆\n",
      "Extra 的outliers 有 3 筆\n",
      "Tip_Amt 的outliers 有 990 筆\n",
      "2015_0106_Yellow_head_50K.csv\n",
      "Speed 的outliers 有 25 筆\n",
      "Fare_Amt 的outliers 有 1022 筆\n",
      "Extra 的outliers 有 679 筆\n",
      "Tip_Amt 的outliers 有 642 筆\n",
      "2015_Green_head_50K.csv\n",
      "Speed 的outliers 有 41 筆\n",
      "Fare_Amt 的outliers 有 800 筆\n",
      "Tip_Amt 的outliers 有 260 筆\n",
      "2016_Green_head_50K.csv\n",
      "Speed 的outliers 有 67 筆\n",
      "Fare_Amt 的outliers 有 717 筆\n",
      "Tip_Amt 的outliers 有 733 筆\n",
      "2016_Yellow_head_50K.csv\n",
      "Speed 的outliers 有 34 筆\n",
      "Fare_Amt 的outliers 有 1591 筆\n",
      "Extra 的outliers 有 174 筆\n",
      "Tip_Amt 的outliers 有 1174 筆\n",
      "2017_Green_head_50K.csv\n",
      "Speed 的outliers 有 87 筆\n",
      "Fare_Amt 的outliers 有 932 筆\n",
      "Tip_Amt 的outliers 有 763 筆\n",
      "2017_Yellow_head_50K.csv\n",
      "Speed 的outliers 有 39 筆\n",
      "Fare_Amt 的outliers 有 1527 筆\n",
      "Extra 的outliers 有 3507 筆\n",
      "Tip_Amt 的outliers 有 735 筆\n"
     ]
    }
   ],
   "source": [
    "#Check Outliers\n",
    "#Speed ,Fare Outliers\n",
    "needCheck=['Speed','Fare_Amt','Extra','Tip_Amt']\n",
    "def detect_outlier(df,col):\n",
    "    tmp = len(df[np.abs(getattr(df, col)-getattr(df, col).mean()) >= (3*getattr(df, col).std())])\n",
    "    if tmp!=0:\n",
    "        print(col,\"的outliers 有\",tmp,\"筆\")\n",
    "\n",
    "j=0\n",
    "for tables in t:\n",
    "    print(files[j])\n",
    "    j+=1\n",
    "    for i in needCheck:\n",
    "        detect_outlier(tables,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48287, 20)\n",
      "(49635, 21)\n",
      "(49554, 21)\n",
      "(49686, 21)\n",
      "(48453, 21)\n",
      "(49611, 21)\n",
      "(48937, 21)\n",
      "(49724, 21)\n",
      "(49535, 21)\n",
      "(49184, 21)\n",
      "(49209, 21)\n",
      "(49687, 18)\n",
      "(49286, 18)\n",
      "(49583, 18)\n"
     ]
    }
   ],
   "source": [
    "for ta in t:\n",
    "    print(ta.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
